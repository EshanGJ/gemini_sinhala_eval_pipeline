{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3becf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a113a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc97b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-google-genai langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38743504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd64d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OCR EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š LAYOUT-AWARE METRICS (Order Matters)\n",
      "------------------------------------------------------------\n",
      "  CER (Character Error Rate):     0.2529\n",
      "  CER Accuracy:                   0.7471\n",
      "  WER (Word Error Rate):          0.2909\n",
      "  WER Accuracy:                   0.7091\n",
      "\n",
      "ðŸ“ CONTENT-ONLY METRICS (Order Ignored)\n",
      "------------------------------------------------------------\n",
      "  Precision:                      0.7707\n",
      "  Recall:                         0.7333\n",
      "  F1 Score:                       0.7516\n",
      "  Correct Words:                  121\n",
      "  Missing Words:                  44\n",
      "  Extra Words:                    36\n",
      "\n",
      "ðŸ”¤ CHARACTER-LEVEL CONTENT METRICS\n",
      "------------------------------------------------------------\n",
      "  Precision:                      0.9725\n",
      "  Recall:                         0.9567\n",
      "  F1 Score:                       0.9645\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import Levenshtein\n",
    "# from collections import Counter\n",
    "\n",
    "# def calculate_layout_aware_metrics(ground_truth: str, extracted_text: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Calculates Character Error Rate (CER) and Word Error Rate (WER) \n",
    "#     using Levenshtein distance. These metrics are LAYOUT-AWARE \n",
    "#     (order matters).\n",
    "#     \"\"\"\n",
    "#     gt_clean = ground_truth.strip()\n",
    "#     ext_clean = extracted_text.strip()\n",
    "    \n",
    "#     # Character Error Rate (CER)\n",
    "#     char_distance = Levenshtein.distance(gt_clean, ext_clean)\n",
    "#     char_length = len(gt_clean)\n",
    "#     cer = char_distance / char_length if char_length > 0 else 0.0\n",
    "    \n",
    "#     # Word Error Rate (WER)\n",
    "#     gt_words = gt_clean.split()\n",
    "#     ext_words = ext_clean.split()\n",
    "#     word_distance = Levenshtein.distance(gt_words, ext_words)\n",
    "#     word_length = len(gt_words)\n",
    "#     wer = word_distance / word_length if word_length > 0 else 0.0\n",
    "    \n",
    "#     return {\n",
    "#         \"Layout_Aware_CER\": round(cer, 4),\n",
    "#         \"Layout_Aware_WER\": round(wer, 4),\n",
    "#         \"Layout_Aware_CER_Accuracy\": round(1 - cer, 4),\n",
    "#         \"Layout_Aware_WER_Accuracy\": round(1 - wer, 4),\n",
    "#     }\n",
    "\n",
    "# def calculate_content_only_metrics(ground_truth: str, extracted_text: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Compares only text content with word frequency, completely \n",
    "#     LAYOUT-AGNOSTIC (order doesn't matter). Best for evaluating \n",
    "#     OCR text extraction quality independent of layout.\n",
    "#     \"\"\"\n",
    "#     gt_clean = ground_truth.strip().lower()\n",
    "#     ext_clean = extracted_text.strip().lower()\n",
    "    \n",
    "#     gt_counter = Counter(gt_clean.split())\n",
    "#     ext_counter = Counter(ext_clean.split())\n",
    "    \n",
    "#     # Words that appear with correct frequency\n",
    "#     correct_counts = sum((gt_counter & ext_counter).values())\n",
    "#     total_gt_words = sum(gt_counter.values())\n",
    "#     total_ext_words = sum(ext_counter.values())\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     recall = correct_counts / total_gt_words if total_gt_words > 0 else 0.0\n",
    "#     precision = correct_counts / total_ext_words if total_ext_words > 0 else 0.0\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "#     # Additional insights\n",
    "#     missing_words = total_gt_words - correct_counts\n",
    "#     extra_words = total_ext_words - correct_counts\n",
    "    \n",
    "#     return {\n",
    "#         \"Content_Precision\": round(precision, 4),\n",
    "#         \"Content_Recall\": round(recall, 4),\n",
    "#         \"Content_F1_Score\": round(f1, 4),\n",
    "#         \"Correct_Words\": correct_counts,\n",
    "#         \"Missing_Words\": missing_words,\n",
    "#         \"Extra_Words\": extra_words,\n",
    "#         \"Total_GT_Words\": total_gt_words,\n",
    "#         \"Total_Extracted_Words\": total_ext_words,\n",
    "#     }\n",
    "\n",
    "# def calculate_character_content_metrics(ground_truth: str, extracted_text: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Character-level content comparison (layout-agnostic).\n",
    "#     Useful for languages with complex word boundaries like Sinhala/Tamil.\n",
    "#     \"\"\"\n",
    "#     gt_clean = ground_truth.strip().lower()\n",
    "#     ext_clean = extracted_text.strip().lower()\n",
    "    \n",
    "#     # Remove all whitespace for pure character comparison\n",
    "#     gt_chars = Counter(gt_clean.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "#     ext_chars = Counter(ext_clean.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\"))\n",
    "    \n",
    "#     correct_chars = sum((gt_chars & ext_chars).values())\n",
    "#     total_gt_chars = sum(gt_chars.values())\n",
    "#     total_ext_chars = sum(ext_chars.values())\n",
    "    \n",
    "#     recall = correct_chars / total_gt_chars if total_gt_chars > 0 else 0.0\n",
    "#     precision = correct_chars / total_ext_chars if total_ext_chars > 0 else 0.0\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "#     return {\n",
    "#         \"Character_Content_Precision\": round(precision, 4),\n",
    "#         \"Character_Content_Recall\": round(recall, 4),\n",
    "#         \"Character_Content_F1\": round(f1, 4),\n",
    "#     }\n",
    "\n",
    "# def evaluate_ocr_from_files(ground_truth_file: str, extracted_text_file: str) -> dict:\n",
    "#     \"\"\"\n",
    "#     Main function to evaluate OCR accuracy from two text files.\n",
    "    \n",
    "#     Args:\n",
    "#         ground_truth_file: Path to the ground truth text file\n",
    "#         extracted_text_file: Path to the extracted/predicted text file\n",
    "        \n",
    "#     Returns:\n",
    "#         Dictionary containing all evaluation metrics\n",
    "#     \"\"\"\n",
    "#     # Read files\n",
    "#     try:\n",
    "#         with open(ground_truth_file, 'r', encoding='utf-8') as f:\n",
    "#             ground_truth = f.read()\n",
    "#         with open(extracted_text_file, 'r', encoding='utf-8') as f:\n",
    "#             extracted_text = f.read()\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"Error: File not found - {e}\")\n",
    "#         return {}\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading files: {e}\")\n",
    "#         return {}\n",
    "    \n",
    "#     # Calculate all metrics\n",
    "#     results = {}\n",
    "    \n",
    "#     # Layout-aware metrics (traditional CER/WER)\n",
    "#     layout_metrics = calculate_layout_aware_metrics(ground_truth, extracted_text)\n",
    "#     results.update(layout_metrics)\n",
    "    \n",
    "#     # Content-only metrics (layout-agnostic)\n",
    "#     content_metrics = calculate_content_only_metrics(ground_truth, extracted_text)\n",
    "#     results.update(content_metrics)\n",
    "    \n",
    "#     # Character-level content metrics\n",
    "#     char_metrics = calculate_character_content_metrics(ground_truth, extracted_text)\n",
    "#     results.update(char_metrics)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def print_results(results: dict):\n",
    "#     \"\"\"Pretty print the evaluation results.\"\"\"\n",
    "#     if not results:\n",
    "#         print(\"No results to display.\")\n",
    "#         return\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*60)\n",
    "#     print(\"OCR EVALUATION RESULTS\")\n",
    "#     print(\"=\"*60)\n",
    "    \n",
    "#     print(\"\\nðŸ“Š LAYOUT-AWARE METRICS (Order Matters)\")\n",
    "#     print(\"-\" * 60)\n",
    "#     print(f\"  CER (Character Error Rate):     {results['Layout_Aware_CER']}\")\n",
    "#     print(f\"  CER Accuracy:                   {results['Layout_Aware_CER_Accuracy']}\")\n",
    "#     print(f\"  WER (Word Error Rate):          {results['Layout_Aware_WER']}\")\n",
    "#     print(f\"  WER Accuracy:                   {results['Layout_Aware_WER_Accuracy']}\")\n",
    "    \n",
    "#     print(\"\\nðŸ“ CONTENT-ONLY METRICS (Order Ignored)\")\n",
    "#     print(\"-\" * 60)\n",
    "#     print(f\"  Precision:                      {results['Content_Precision']}\")\n",
    "#     print(f\"  Recall:                         {results['Content_Recall']}\")\n",
    "#     print(f\"  F1 Score:                       {results['Content_F1_Score']}\")\n",
    "#     print(f\"  Correct Words:                  {results['Correct_Words']}\")\n",
    "#     print(f\"  Missing Words:                  {results['Missing_Words']}\")\n",
    "#     print(f\"  Extra Words:                    {results['Extra_Words']}\")\n",
    "    \n",
    "#     print(\"\\nðŸ”¤ CHARACTER-LEVEL CONTENT METRICS\")\n",
    "#     print(\"-\" * 60)\n",
    "#     print(f\"  Precision:                      {results['Character_Content_Precision']}\")\n",
    "#     print(f\"  Recall:                         {results['Character_Content_Recall']}\")\n",
    "#     print(f\"  F1 Score:                       {results['Character_Content_F1']}\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# # === USAGE EXAMPLE ===\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Specify your file paths\n",
    "#     ground_truth_file = \"original.txt\"\n",
    "#     extracted_text_file = \"predicted.txt\"\n",
    "    \n",
    "#     # Run evaluation\n",
    "#     results = evaluate_ocr_from_files(ground_truth_file, extracted_text_file)\n",
    "    \n",
    "#     # Display results\n",
    "#     print_results(results)\n",
    "    \n",
    "#     # Optionally save results to JSON\n",
    "#     # import json\n",
    "#     # with open('evaluation_results.json', 'w') as f:\n",
    "#     #     json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0741a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "class MarkdownEvaluator:\n",
    "    def __init__(self, header_threshold=0.8):\n",
    "        self.header_threshold = header_threshold\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalizes text for comparison:\n",
    "        1. Removes markdown formatting (*, _, `) but KEEPS pipes | for tables.\n",
    "        2. Normalizes whitespace.\n",
    "        3. Lowers case (optional, strictness depends on use case).\n",
    "        \"\"\"\n",
    "        # Remove bold/italic/code markers\n",
    "        text = re.sub(r'[*_`]', '', text) \n",
    "        # Normalize whitespace (tabs/newlines -> single space)\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    def parse_markdown(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parses text into sections. \n",
    "        If no headers (#) are found, treats the whole text as a 'Document' section.\n",
    "        \"\"\"\n",
    "        # Regex for standard Markdown headers (# Header)\n",
    "        pattern = re.compile(r'(^|\\n)(#+)\\s*(.*?)(?=\\n#|\\Z)', re.DOTALL)\n",
    "        sections = {}\n",
    "        \n",
    "        matches = list(pattern.finditer(text))\n",
    "        \n",
    "        # FAILSAFE: If no headers found, treat entire text as body content\n",
    "        if not matches:\n",
    "            sections['Whole Document'] = {\n",
    "                'title': 'Whole Document',\n",
    "                'content': text.strip()\n",
    "            }\n",
    "            return sections\n",
    "\n",
    "        # If headers exist, parse normally\n",
    "        if matches[0].start() > 0:\n",
    "            preamble = text[:matches[0].start()].strip()\n",
    "            if preamble:\n",
    "                sections['PREAMBLE'] = {'title': 'PREAMBLE', 'content': preamble}\n",
    "\n",
    "        for match in matches:\n",
    "            hashes, title, content = match.group(2), match.group(3), match.group(0)\n",
    "            # Remove the header line itself from the content to avoid duplication\n",
    "            content_only = content.replace(f\"{hashes} {title}\", \"\", 1).strip()\n",
    "            \n",
    "            sections[title.strip()] = {\n",
    "                'title': title.strip(),\n",
    "                'content': content_only\n",
    "            }\n",
    "            \n",
    "        return sections\n",
    "\n",
    "    def get_diff_highlight(self, a: str, b: str) -> str:\n",
    "        \"\"\"Helper to show exactly where characters differ.\"\"\"\n",
    "        s = SequenceMatcher(None, a, b)\n",
    "        diff_out = []\n",
    "        for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "            if tag == 'replace':\n",
    "                diff_out.append(f\"MISMATCH: '{a[i1:i2]}' vs '{b[j1:j2]}'\")\n",
    "            elif tag == 'delete':\n",
    "                diff_out.append(f\"MISSING in Pred: '{a[i1:i2]}'\")\n",
    "            elif tag == 'insert':\n",
    "                diff_out.append(f\"EXTRA in Pred: '{b[j1:j2]}'\")\n",
    "        return \" | \".join(diff_out)\n",
    "\n",
    "    def evaluate(self, gt_text: str, pred_text: str) -> dict:\n",
    "        gt_sections = self.parse_markdown(gt_text)\n",
    "        pred_sections = self.parse_markdown(pred_text)\n",
    "        \n",
    "        results = {'matches': [], 'score_sum': 0, 'count': 0}\n",
    "        \n",
    "        # Combine Title + Content for comparison to catch everything\n",
    "        def get_full_text(sec):\n",
    "            # If it's the \"Whole Document\" fallback, just return content\n",
    "            if sec['title'] == 'Whole Document':\n",
    "                return sec['content']\n",
    "            return f\"{sec['title']} {sec['content']}\"\n",
    "\n",
    "        matched_pred_keys = set()\n",
    "\n",
    "        for gt_key, gt_data in gt_sections.items():\n",
    "            best_match = None\n",
    "            best_score = 0.0\n",
    "            \n",
    "            gt_full_clean = self.clean_text(get_full_text(gt_data))\n",
    "            \n",
    "            # Find best matching section in Pred\n",
    "            for pred_key, pred_data in pred_sections.items():\n",
    "                if pred_key in matched_pred_keys: continue\n",
    "                \n",
    "                # Compare fuzzy headers, OR if we are in \"Whole Document\" mode, compare full text\n",
    "                if gt_key == \"Whole Document\" or pred_key == \"Whole Document\":\n",
    "                     # If parsing failed, we force a comparison of the body\n",
    "                    header_sim = 1.0 \n",
    "                else:\n",
    "                    header_sim = SequenceMatcher(None, gt_key, pred_key).ratio()\n",
    "\n",
    "                if header_sim > self.header_threshold:\n",
    "                    pred_full_clean = self.clean_text(get_full_text(pred_data))\n",
    "                    content_sim = SequenceMatcher(None, gt_full_clean, pred_full_clean).ratio()\n",
    "                    \n",
    "                    if content_sim > best_score:\n",
    "                        best_score = content_sim\n",
    "                        best_match = pred_key\n",
    "\n",
    "            if best_match:\n",
    "                matched_pred_keys.add(best_match)\n",
    "                \n",
    "                # Get raw texts for diffing\n",
    "                gt_raw = self.clean_text(get_full_text(gt_data))\n",
    "                pred_raw = self.clean_text(get_full_text(pred_sections[best_match]))\n",
    "                \n",
    "                print(f\"Cleaned ground truth: {gt_raw}\")\n",
    "                print(f\"Cleaned prediction  : {pred_raw}\")\n",
    "\n",
    "                diff_notes = \"\"\n",
    "                if best_score < 1.0:\n",
    "                    diff_notes = self.get_diff_highlight(gt_raw, pred_raw)\n",
    "\n",
    "                results['matches'].append({\n",
    "                    'section': gt_key,\n",
    "                    'score': best_score,\n",
    "                    'diff': diff_notes\n",
    "                })\n",
    "                results['score_sum'] += best_score\n",
    "                results['count'] += 1\n",
    "            else:\n",
    "                # Missing section penalty\n",
    "                results['matches'].append({'section': gt_key, 'score': 0.0, 'diff': \"Section Missing\"})\n",
    "                results['count'] += 1\n",
    "\n",
    "        results['final_score'] = results['score_sum'] / results['count'] if results['count'] > 0 else 0\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc37eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned ground truth: 03. à¶šà·ƒà·Šà¶»à·” à·„à· à¶¢à¶¸à·Šà¶‹ à¶šà·’à¶»à·“à¶¸à¶§ à¶œà¶¸à¶±à¶¯ à¶¯à·’à¶œ à¶œà¶¸à¶±à¶šà·Š à·€à·’à¶º à¶ºà·”à¶­à·”à¶º. à¶¸à·™à¶¸ à·€à¶»à¶´â€à·Šâ€à¶»à·ƒà·à¶¯à¶º à¶œà¶¸à·Š à¶´â€à·Šâ€à¶»à¶¯à·šà·à¶ºà·š à·ƒà·“à¶¸à·à·€ à¶‰à¶šà·Šà¶¸à·€à·– à·€à·’à¶œà·ƒ à¶¸ à¶‡à¶»à¶¹à·š. à¶‘à¶¸à·™à¶±à·Š à¶¸ à¶¢à¶¸à·Šà¶‹ à¶­à¶ƒà¶šà·“à¶»à·Š à¶‰à¶§à·”à¶šà¶»à¶±à·Šà¶±à· à¶…à¶¯à·à·… à·ƒà¶½à·à¶­à¶ºà·š à·€à·šà¶½à·à·€ à¶‰à¶šà·Šà¶¸à·€à·“à¶¸à¶§ à¶´à·™à¶» à¶…à¶±à·™à¶šà·Š à·ƒà¶½à·à¶­à¶º à·„à· à¶‘à¶šà·Š à¶šà·œà¶§ à¶‰à¶§à·” à¶šà¶»à¶± à¶¶à·€à¶§ à¶±à·’à¶ºà·’à¶ºà¶­à¶º à¶­à·à¶¶à·’à¶º à¶ºà·”à¶­à·” à¶º. 04. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à· à·†à¶¢à·Šà¶»à·Šà·„à·’ à·ƒà·”à¶±à·Šà¶±à¶­à·Š à·ƒà¶½à·à¶­à¶ºà¶±à·Š à·„à· à·€à·’à¶­à·Šà¶»à·Š à·ƒà¶½à·à¶­à¶ºà¶±à·Š à¶±à·œà¶šà¶©à·€à· à¶‰à¶§à·” à¶šà·’à¶»à·“à¶¸ à¶ºà·„à¶´à¶­à·Š à¶º. 05. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š à¶¢à¶¸à·Šà¶‹ à¶šà¶»à¶± à·€à·’à¶§ à·ƒà¶½à·à¶­à·Š à¶¯à·™à¶šà¶šà¶§ à¶‘à¶šà·Š à¶…à¶¯à·à¶±à¶ºà¶šà·Š à¶¯, à¶‘à¶šà·’à¶±à·™à¶š à·ƒà¶½à·à¶­à¶ºà¶±à·Š à¶‘à¶šà·’à¶±à·™à¶šà¶§ à·€à·™à¶±à·Š à·€à·™à¶±à·Š à·€à·à¶ºà·™à¶±à·Š à¶‰à¶šà·à¶¸à¶­à·Š à¶¯ à¶šà·’à·€ à·„à·à¶šà·’ à¶º. 06. à¶šà·™à¶§à·’ à¶šà¶» à·ƒà¶½à·à¶­à¶º à¶‰à¶§à·” à¶šà¶»à¶±à·Šà¶±à¶±à·Š, à·ƒà¶½à·à¶­à¶º à·ƒà¶¸à·Šà¶´à·–à¶»à·Šà¶« à·€à·à¶ºà·™à¶±à·Š à¶‰à¶§à·” à¶šà¶»à¶± à¶‰à¶¸à·à¶¸à·Šà·€à¶»à¶ºà· à¶´à·’à·…à·’à¶´à·à¶¯à·’à¶º à¶±à·œà·„à·à¶šà·’ à¶º. à¶…à¶·à·Šâ€à¶ºà·à·ƒ à¶´à·„à¶­ à¶´â€à·Šâ€à¶»à¶šà·à· à·„à¶»à·’ à¶±à¶¸à·Š ( âœ” ) à¶½à¶šà·”à¶« à¶¯, à·€à·à¶»à¶¯à·’ à¶±à¶¸à·Š ( x ) à¶½à¶šà·”à¶« à¶¯ à·€à¶»à·„à¶±à·Š à¶­à·”à·… à¶ºà·œà¶¯à¶±à·Šà¶±. à¶…) 1. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·™à¶šà·”à¶§ à·ƒà¶½à·à¶­à·Š à¶šà·’à¶»à·“à¶¸ à¶…à¶´à·„à·ƒà·” à¶±à¶¸à·Š à¶šà¶½à· à¶šà·… à·„à·à¶šà·’ à¶º. 2. à·†à¶¢à·Šà¶»à·Š à·ƒà¶½à·à¶­à¶º à¶šà·™à¶§à·’ à¶šà¶» à·„à· à¶‘à¶šà¶­à·” à¶šà¶» à¶‰à¶§à·”à¶šà·… à¶±à·œà·„à·à¶šà·’ à¶º. 3. â€˜à¶¢à¶¸à·Šà¶‹ à¶­à¶šà·Šà¶¯à·“à¶¸à·Šâ€™ à¶ºà¶±à·” à¶´à·™à¶»à¶§à·” à¶šà¶» à·ƒà¶½à·à¶­à·Š à¶‰à¶§à·” à¶šà·’à¶»à·“à¶¸à¶ºà·’. 4. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š à¶šà·’à·ƒà·’ à¶¸ à·ƒà·”à¶±à·Šà¶±à¶­à·Š à·ƒà¶½à·à¶­à¶ºà¶šà·Š à¶‰à¶§à·” à¶šà·’à¶»à·“à¶¸ à¶…à·€à·à·Šâ€à¶º à¶±à·œà·€à·š. (à¶†) à¶”à¶¶ à¶¢à·“à·€à·’à¶­à¶ºà·š à¶šà·ƒà·Šà¶»à·” à¶¢à¶¸à·Šà¶‹ à¶šà·… à¶…à¶­à·Šà¶¯à·à¶šà·“à¶¸à¶šà·Š à¶šà·™à¶§à·’à¶ºà·™à¶±à·Š à·€à·’à¶œâ€à·Šâ€à¶»à·„ à¶šà¶»à¶±à·Šà¶±.\n",
      "Cleaned prediction  : 03. à¶šà·ƒà·Šà¶»à·” à·„à· à¶¢à¶¸à·Šà¶‹ à¶šà·’à¶»à·“à¶¸à¶§ à¶œà¶¸à¶± à¶¯ à¶¯à·’à¶œ à¶œà¶¸à¶±à¶šà·Š à·€à·’à¶º à¶ºà·”à¶­à·”à¶º. à¶¸à·™à¶¸ à·€à¶»à¶´â€à·Šâ€à¶»à·ƒà·à¶¯à¶º à¶œà¶¸à·Š à¶´â€à·Šâ€à¶»à¶¯à·šà·à¶ºà·š à·ƒà·“à¶¸à·à·€ à¶‰à¶šà·Šà¶¸à·€à·– à·€à·’à¶œà·ƒ à¶¸ à¶‡à¶»à¶¹à·š. à¶‘à¶¸à·™à¶±à·Š à¶¸ à¶¢à¶¸à·Šà¶‹ à¶­à¶ƒà¶šà·“à¶»à·Š à¶‰à¶§à·”à¶šà¶»à¶±à·Šà¶±à· à¶…à¶¯à·à·… à·ƒà¶½à·à¶­à¶ºà·š à·€à·šà¶½à·à·€ à¶‰à¶šà·Šà¶¸à·€à·“à¶¸à¶§ à¶´à·™à¶» à¶…à¶±à·™à¶šà·Š à·ƒà¶½à·à¶­à¶º à·„à· à¶‘à¶šà·Š à¶šà·œà¶§ à¶‰à¶§à·” à¶šà¶»à¶± à¶¶à·€à¶§ à¶±à·’à¶ºà·’à¶ºà¶­à¶º à¶­à·à¶¶à·’à¶º à¶ºà·”à¶­à·” à¶º. 04. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à· à·†à¶¢à·Šà¶»à·Šà·„à·’ à·ƒà·”à¶±à·Šà¶±à¶­à·Š à·ƒà¶½à·à¶­à¶ºà¶±à·Š à·„à· à·€à·’à¶­à·Šà¶»à·Š à·ƒà¶½à·à¶­à¶ºà¶±à·Š à¶±à·œà¶šà¶©à·€à· à¶‰à¶§à·” à¶šà·’à¶»à·“à¶¸ à¶ºà·„à¶´à¶­à·Š à¶º. 05. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š à¶¢à¶¸à·Šà¶‹ à¶šà¶»à¶± à·€à·’à¶§ à·ƒà¶½à·à¶­à·Š à¶¯à·™à¶šà¶šà¶§ à¶‘à¶šà·Š à¶…à¶¯à·à¶±à¶ºà¶šà·Š à¶¯, à¶‘à¶šà·’à¶±à·™à¶š à·ƒà¶½à·à¶­à¶ºà¶±à·Š à¶‘à¶šà·’à¶±à·™à¶šà¶§ à·€à·™à¶±à·Š à·€à·™à¶±à·Š à·€à·à¶ºà·™à¶±à·Š à¶‰à¶šà·à¶¸à¶­à·Š à¶¯ à¶šà·’à·€ à·„à·à¶šà·’ à¶º. 06. à¶šà·™à¶§à·’ à¶šà¶» à·ƒà¶½à·à¶­à¶º à¶‰à¶§à·” à¶šà¶»à¶±à·Šà¶±à¶±à·Š, à·ƒà¶½à·à¶­à¶º à·ƒà¶¸à·Šà¶´à·–à¶»à·Šà¶« à·€à·à¶ºà·™à¶±à·Š à¶‰à¶§à·” à¶šà¶»à¶± à¶‰à¶¸à·à¶¸à·Šà·€à¶»à¶ºà· à¶´à·’à·…à·’à¶´à·à¶¯à·’à¶º à¶±à·œà·„à·à¶šà·’ à¶º. à¶…à¶·à·Šâ€à¶ºà·à·ƒ à¶´à·„à¶­ à¶´â€à·Šâ€à¶»à¶šà·à· à·„à¶»à·’ à¶±à¶¸à·Š ( âœ” ) à¶½à¶šà·”à¶« à¶¯, à·€à·à¶»à¶¯à·’ à¶±à¶¸à·Š ( x ) à¶½à¶šà·”à¶« à¶¯ à·€à¶»à·„à¶±à·Š à¶­à·”à·… à¶ºà·œà¶¯à¶±à·Šà¶±. (à¶…) 1. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·™à¶šà·”à¶§ à·ƒà¶½à·à¶­à·Š à¶šà·’à¶»à·“à¶¸ à¶…à¶´à·„à·ƒà·” à¶±à¶¸à·Š à¶šà¶½à· à¶šà·… à·„à·à¶šà·’ à¶º. 2. à·†à¶¢à·Šà¶»à·Š à·ƒà¶½à·à¶­à¶º à¶šà·™à¶§à·’ à¶šà¶» à·„à· à¶‘à¶šà¶­à·” à¶šà¶» à¶‰à¶§à·”à¶šà·… à¶±à·œà·„à·à¶šà·’ à¶º. 3. â€˜à¶¢à¶¸à·Šà¶‹ à¶­à¶šà·Šà¶¯à·“à¶¸à·Šâ€™ à¶ºà¶±à·” à¶´à·™à¶»à¶§à·” à¶šà¶» à·ƒà¶½à·à¶­à·Š à¶‰à¶§à·” à¶šà·’à¶»à·“à¶¸à¶ºà·’. 4. à¶œà¶¸à¶±à·™à·„à·’ à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š à¶šà·’à·ƒà·’ à¶¸ à·ƒà·”à¶±à·Šà¶±à¶­à·Š à·ƒà¶½à·à¶­à¶ºà¶šà·Š à¶‰à¶§à·” à¶šà·’à¶»à·“à¶¸ à¶…à·€à·à·Šâ€à¶º à¶±à·œà·€à·š. (à¶†) à¶”à¶¶ à¶¢à·“à·€à·’à¶­à¶ºà·š à¶šà·ƒà·Šà¶»à·” à¶¢à¶¸à·Šà¶‹ à¶šà·… à¶…à¶­à·Šà¶¯à·à¶šà·“à¶¸à¶šà·Š à¶šà·™à¶§à·’à¶ºà·™à¶±à·Š à·€à·’à¶œâ€à·Šâ€à¶»à·„ à¶šà¶»à¶±à·Šà¶±.\n",
      "Overall Score: 0.9989\n",
      "----------------------------------------\n",
      "Section: Whole Document\n",
      "Score:   0.9989\n",
      "Errors:  EXTRA in Pred: ' ' | EXTRA in Pred: '('\n"
     ]
    }
   ],
   "source": [
    "gt = \"\"\n",
    "pred = \"\"\n",
    "with open(\"o.txt\", \"r\") as original_file:\n",
    "    for line in original_file.readlines():\n",
    "        gt = gt + \"\\n\" + line\n",
    "\n",
    "with open(\"p.txt\", \"r\") as pred_file:\n",
    "    for line in pred_file.readlines():\n",
    "        pred = pred + \"\\n\" + line\n",
    "\n",
    "evaluator = MarkdownEvaluator()\n",
    "metrics = evaluator.evaluate(gt, pred)\n",
    "\n",
    "print(f\"Overall Score: {metrics['final_score']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "for m in metrics['matches']:\n",
    "    print(f\"Section: {m['section']}\")\n",
    "    print(f\"Score:   {m['score']:.4f}\")\n",
    "    if m['diff']:\n",
    "        print(f\"Errors:  {m['diff']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f00296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth words: ['03.', 'à¶šà·ƒà·Šà¶»à·”', 'à·„à·', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·’à¶»à·“à¶¸à¶§', 'à¶œà¶¸à¶±à¶¯', 'à¶¯à·’à¶œ', 'à¶œà¶¸à¶±à¶šà·Š', 'à·€à·’à¶º', 'à¶ºà·”à¶­à·”à¶º.', 'à¶¸à·™à¶¸', 'à·€à¶»à¶´\\u200dà·Š\\u200dà¶»à·ƒà·à¶¯à¶º', 'à¶œà¶¸à·Š', 'à¶´\\u200dà·Š\\u200dà¶»à¶¯à·šà·à¶ºà·š', 'à·ƒà·“à¶¸à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·–', 'à·€à·’à¶œà·ƒ', 'à¶¸', 'à¶‡à¶»à¶¹à·š.', 'à¶‘à¶¸à·™à¶±à·Š', 'à¶¸', 'à¶¢à¶¸à·Šà¶‹', 'à¶­à¶ƒà¶šà·“à¶»à·Š', 'à¶‰à¶§à·”à¶šà¶»à¶±à·Šà¶±à·', 'à¶…à¶¯à·à·…', 'à·ƒà¶½à·à¶­à¶ºà·š', 'à·€à·šà¶½à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·“à¶¸à¶§', 'à¶´à·™à¶»', 'à¶…à¶±à·™à¶šà·Š', 'à·ƒà¶½à·à¶­à¶º', 'à·„à·', 'à¶‘à¶šà·Š', 'à¶šà·œà¶§', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶¶à·€à¶§', 'à¶±à·’à¶ºà·’à¶ºà¶­à¶º', 'à¶­à·à¶¶à·’à¶º', 'à¶ºà·”à¶­à·”', 'à¶º.', '04.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·', 'à·†à¶¢à·Šà¶»à·Šà·„à·’', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à·„à·', 'à·€à·’à¶­à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶±à·œà¶šà¶©à·€à·', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶ºà·„à¶´à¶­à·Š', 'à¶º.', '05.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà¶»à¶±', 'à·€à·’à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶¯à·™à¶šà¶šà¶§', 'à¶‘à¶šà·Š', 'à¶…à¶¯à·à¶±à¶ºà¶šà·Š', 'à¶¯,', 'à¶‘à¶šà·’à¶±à·™à¶š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶‘à¶šà·’à¶±à·™à¶šà¶§', 'à·€à·™à¶±à·Š', 'à·€à·™à¶±à·Š', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶šà·à¶¸à¶­à·Š', 'à¶¯', 'à¶šà·’à·€', 'à·„à·à¶šà·’', 'à¶º.', '06.', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à¶º', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±à·Šà¶±à¶±à·Š,', 'à·ƒà¶½à·à¶­à¶º', 'à·ƒà¶¸à·Šà¶´à·–à¶»à·Šà¶«', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶‰à¶¸à·à¶¸à·Šà·€à¶»à¶ºà·', 'à¶´à·’à·…à·’à¶´à·à¶¯à·’à¶º', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '**à¶…à¶·à·Š\\u200dà¶ºà·à·ƒ**', 'à¶´à·„à¶­', 'à¶´\\u200dà·Š\\u200dà¶»à¶šà·à·', 'à·„à¶»à·’', 'à¶±à¶¸à·Š', '(', 'âœ”', ')', 'à¶½à¶šà·”à¶«', 'à¶¯,', 'à·€à·à¶»à¶¯à·’', 'à¶±à¶¸à·Š', '(', 'x', ')', 'à¶½à¶šà·”à¶«', 'à¶¯', 'à·€à¶»à·„à¶±à·Š', 'à¶­à·”à·…', 'à¶ºà·œà¶¯à¶±à·Šà¶±.', 'à¶…)', '1.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·™à¶šà·”à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à¶´à·„à·ƒà·”', 'à¶±à¶¸à·Š', 'à¶šà¶½à·', 'à¶šà·…', 'à·„à·à¶šà·’', 'à¶º.', '2.', 'à·†à¶¢à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶º', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·„à·', 'à¶‘à¶šà¶­à·”', 'à¶šà¶»', 'à¶‰à¶§à·”à¶šà·…', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '3.', 'â€˜à¶¢à¶¸à·Šà¶‹', 'à¶­à¶šà·Šà¶¯à·“à¶¸à·Šâ€™', 'à¶ºà¶±à·”', 'à¶´à·™à¶»à¶§à·”', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸à¶ºà·’.', '4.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶šà·’à·ƒà·’', 'à¶¸', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶šà·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à·€à·à·Š\\u200dà¶º', 'à¶±à·œà·€à·š.', '(à¶†)', 'à¶”à¶¶', 'à¶¢à·“à·€à·’à¶­à¶ºà·š', 'à¶šà·ƒà·Šà¶»à·”', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·…', 'à¶…à¶­à·Šà¶¯à·à¶šà·“à¶¸à¶šà·Š', 'à¶šà·™à¶§à·’à¶ºà·™à¶±à·Š', 'à·€à·’à¶œ\\u200dà·Š\\u200dà¶»à·„', 'à¶šà¶»à¶±à·Šà¶±.']\n",
      "Prediction words: ['03.', 'à¶šà·ƒà·Šà¶»à·”', 'à·„à·', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·’à¶»à·“à¶¸à¶§', 'à¶œà¶¸à¶±', 'à¶¯', 'à¶¯à·’à¶œ', 'à¶œà¶¸à¶±à¶šà·Š', 'à·€à·’à¶º', 'à¶ºà·”à¶­à·”à¶º.', 'à¶¸à·™à¶¸', 'à·€à¶»à¶´\\u200dà·Š\\u200dà¶»à·ƒà·à¶¯à¶º', 'à¶œà¶¸à·Š', 'à¶´\\u200dà·Š\\u200dà¶»à¶¯à·šà·à¶ºà·š', 'à·ƒà·“à¶¸à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·–', 'à·€à·’à¶œà·ƒ', 'à¶¸', 'à¶‡à¶»à¶¹à·š.', 'à¶‘à¶¸à·™à¶±à·Š', 'à¶¸', 'à¶¢à¶¸à·Šà¶‹', 'à¶­à¶ƒà¶šà·“à¶»à·Š', 'à¶‰à¶§à·”à¶šà¶»à¶±à·Šà¶±à·', 'à¶…à¶¯à·à·…', 'à·ƒà¶½à·à¶­à¶ºà·š', 'à·€à·šà¶½à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·“à¶¸à¶§', 'à¶´à·™à¶»', 'à¶…à¶±à·™à¶šà·Š', 'à·ƒà¶½à·à¶­à¶º', 'à·„à·', 'à¶‘à¶šà·Š', 'à¶šà·œà¶§', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶¶à·€à¶§', 'à¶±à·’à¶ºà·’à¶ºà¶­à¶º', 'à¶­à·à¶¶à·’à¶º', 'à¶ºà·”à¶­à·”', 'à¶º.', '04.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·', 'à·†à¶¢à·Šà¶»à·Šà·„à·’', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à·„à·', 'à·€à·’à¶­à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶±à·œà¶šà¶©à·€à·', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶ºà·„à¶´à¶­à·Š', 'à¶º.', '05.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà¶»à¶±', 'à·€à·’à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶¯à·™à¶šà¶šà¶§', 'à¶‘à¶šà·Š', 'à¶…à¶¯à·à¶±à¶ºà¶šà·Š', 'à¶¯,', 'à¶‘à¶šà·’à¶±à·™à¶š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶‘à¶šà·’à¶±à·™à¶šà¶§', 'à·€à·™à¶±à·Š', 'à·€à·™à¶±à·Š', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶šà·à¶¸à¶­à·Š', 'à¶¯', 'à¶šà·’à·€', 'à·„à·à¶šà·’', 'à¶º.', '06.', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à¶º', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±à·Šà¶±à¶±à·Š,', 'à·ƒà¶½à·à¶­à¶º', 'à·ƒà¶¸à·Šà¶´à·–à¶»à·Šà¶«', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶‰à¶¸à·à¶¸à·Šà·€à¶»à¶ºà·', 'à¶´à·’à·…à·’à¶´à·à¶¯à·’à¶º', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '**à¶…à¶·à·Š\\u200dà¶ºà·à·ƒ**', 'à¶´à·„à¶­', 'à¶´\\u200dà·Š\\u200dà¶»à¶šà·à·', 'à·„à¶»à·’', 'à¶±à¶¸à·Š', '(', 'âœ”', ')', 'à¶½à¶šà·”à¶«', 'à¶¯,', 'à·€à·à¶»à¶¯à·’', 'à¶±à¶¸à·Š', '(', 'x', ')', 'à¶½à¶šà·”à¶«', 'à¶¯', 'à·€à¶»à·„à¶±à·Š', 'à¶­à·”à·…', 'à¶ºà·œà¶¯à¶±à·Šà¶±.', '(à¶…)', '1.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·™à¶šà·”à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à¶´à·„à·ƒà·”', 'à¶±à¶¸à·Š', 'à¶šà¶½à·', 'à¶šà·…', 'à·„à·à¶šà·’', 'à¶º.', '2.', 'à·†à¶¢à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶º', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·„à·', 'à¶‘à¶šà¶­à·”', 'à¶šà¶»', 'à¶‰à¶§à·”à¶šà·…', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '3.', 'â€˜à¶¢à¶¸à·Šà¶‹', 'à¶­à¶šà·Šà¶¯à·“à¶¸à·Šâ€™', 'à¶ºà¶±à·”', 'à¶´à·™à¶»à¶§à·”', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸à¶ºà·’.', '4.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶šà·’à·ƒà·’', 'à¶¸', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶šà·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à·€à·à·Š\\u200dà¶º', 'à¶±à·œà·€à·š.', '(à¶†)', 'à¶”à¶¶', 'à¶¢à·“à·€à·’à¶­à¶ºà·š', 'à¶šà·ƒà·Šà¶»à·”', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·…', 'à¶…à¶­à·Šà¶¯à·à¶šà·“à¶¸à¶šà·Š', 'à¶šà·™à¶§à·’à¶ºà·™à¶±à·Š', 'à·€à·’à¶œ\\u200dà·Š\\u200dà¶»à·„', 'à¶šà¶»à¶±à·Šà¶±.']\n",
      "\n",
      "======================================================================\n",
      "OPCODES EXPLAINED\n",
      "======================================================================\n",
      "\n",
      "Format: (operation, gt_start, gt_end, pred_start, pred_end)\n",
      "\n",
      "Operation: EQUAL\n",
      "  GT indices:   [0:5] â†’ ['03.', 'à¶šà·ƒà·Šà¶»à·”', 'à·„à·', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·’à¶»à·“à¶¸à¶§']\n",
      "  Pred indices: [0:5] â†’ ['03.', 'à¶šà·ƒà·Šà¶»à·”', 'à·„à·', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·’à¶»à·“à¶¸à¶§']\n",
      "\n",
      "Operation: REPLACE\n",
      "  GT indices:   [5:6] â†’ ['à¶œà¶¸à¶±à¶¯']\n",
      "  Pred indices: [5:7] â†’ ['à¶œà¶¸à¶±', 'à¶¯']\n",
      "\n",
      "Operation: EQUAL\n",
      "  GT indices:   [6:112] â†’ ['à¶¯à·’à¶œ', 'à¶œà¶¸à¶±à¶šà·Š', 'à·€à·’à¶º', 'à¶ºà·”à¶­à·”à¶º.', 'à¶¸à·™à¶¸', 'à·€à¶»à¶´\\u200dà·Š\\u200dà¶»à·ƒà·à¶¯à¶º', 'à¶œà¶¸à·Š', 'à¶´\\u200dà·Š\\u200dà¶»à¶¯à·šà·à¶ºà·š', 'à·ƒà·“à¶¸à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·–', 'à·€à·’à¶œà·ƒ', 'à¶¸', 'à¶‡à¶»à¶¹à·š.', 'à¶‘à¶¸à·™à¶±à·Š', 'à¶¸', 'à¶¢à¶¸à·Šà¶‹', 'à¶­à¶ƒà¶šà·“à¶»à·Š', 'à¶‰à¶§à·”à¶šà¶»à¶±à·Šà¶±à·', 'à¶…à¶¯à·à·…', 'à·ƒà¶½à·à¶­à¶ºà·š', 'à·€à·šà¶½à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·“à¶¸à¶§', 'à¶´à·™à¶»', 'à¶…à¶±à·™à¶šà·Š', 'à·ƒà¶½à·à¶­à¶º', 'à·„à·', 'à¶‘à¶šà·Š', 'à¶šà·œà¶§', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶¶à·€à¶§', 'à¶±à·’à¶ºà·’à¶ºà¶­à¶º', 'à¶­à·à¶¶à·’à¶º', 'à¶ºà·”à¶­à·”', 'à¶º.', '04.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·', 'à·†à¶¢à·Šà¶»à·Šà·„à·’', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à·„à·', 'à·€à·’à¶­à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶±à·œà¶šà¶©à·€à·', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶ºà·„à¶´à¶­à·Š', 'à¶º.', '05.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà¶»à¶±', 'à·€à·’à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶¯à·™à¶šà¶šà¶§', 'à¶‘à¶šà·Š', 'à¶…à¶¯à·à¶±à¶ºà¶šà·Š', 'à¶¯,', 'à¶‘à¶šà·’à¶±à·™à¶š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶‘à¶šà·’à¶±à·™à¶šà¶§', 'à·€à·™à¶±à·Š', 'à·€à·™à¶±à·Š', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶šà·à¶¸à¶­à·Š', 'à¶¯', 'à¶šà·’à·€', 'à·„à·à¶šà·’', 'à¶º.', '06.', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à¶º', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±à·Šà¶±à¶±à·Š,', 'à·ƒà¶½à·à¶­à¶º', 'à·ƒà¶¸à·Šà¶´à·–à¶»à·Šà¶«', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶‰à¶¸à·à¶¸à·Šà·€à¶»à¶ºà·', 'à¶´à·’à·…à·’à¶´à·à¶¯à·’à¶º', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '**à¶…à¶·à·Š\\u200dà¶ºà·à·ƒ**', 'à¶´à·„à¶­', 'à¶´\\u200dà·Š\\u200dà¶»à¶šà·à·', 'à·„à¶»à·’', 'à¶±à¶¸à·Š', '(', 'âœ”', ')', 'à¶½à¶šà·”à¶«', 'à¶¯,', 'à·€à·à¶»à¶¯à·’', 'à¶±à¶¸à·Š', '(', 'x', ')', 'à¶½à¶šà·”à¶«', 'à¶¯', 'à·€à¶»à·„à¶±à·Š', 'à¶­à·”à·…', 'à¶ºà·œà¶¯à¶±à·Šà¶±.']\n",
      "  Pred indices: [7:113] â†’ ['à¶¯à·’à¶œ', 'à¶œà¶¸à¶±à¶šà·Š', 'à·€à·’à¶º', 'à¶ºà·”à¶­à·”à¶º.', 'à¶¸à·™à¶¸', 'à·€à¶»à¶´\\u200dà·Š\\u200dà¶»à·ƒà·à¶¯à¶º', 'à¶œà¶¸à·Š', 'à¶´\\u200dà·Š\\u200dà¶»à¶¯à·šà·à¶ºà·š', 'à·ƒà·“à¶¸à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·–', 'à·€à·’à¶œà·ƒ', 'à¶¸', 'à¶‡à¶»à¶¹à·š.', 'à¶‘à¶¸à·™à¶±à·Š', 'à¶¸', 'à¶¢à¶¸à·Šà¶‹', 'à¶­à¶ƒà¶šà·“à¶»à·Š', 'à¶‰à¶§à·”à¶šà¶»à¶±à·Šà¶±à·', 'à¶…à¶¯à·à·…', 'à·ƒà¶½à·à¶­à¶ºà·š', 'à·€à·šà¶½à·à·€', 'à¶‰à¶šà·Šà¶¸à·€à·“à¶¸à¶§', 'à¶´à·™à¶»', 'à¶…à¶±à·™à¶šà·Š', 'à·ƒà¶½à·à¶­à¶º', 'à·„à·', 'à¶‘à¶šà·Š', 'à¶šà·œà¶§', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶¶à·€à¶§', 'à¶±à·’à¶ºà·’à¶ºà¶­à¶º', 'à¶­à·à¶¶à·’à¶º', 'à¶ºà·”à¶­à·”', 'à¶º.', '04.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·', 'à·†à¶¢à·Šà¶»à·Šà·„à·’', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à·„à·', 'à·€à·’à¶­à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶±à·œà¶šà¶©à·€à·', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶ºà·„à¶´à¶­à·Š', 'à¶º.', '05.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà¶»à¶±', 'à·€à·’à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶¯à·™à¶šà¶šà¶§', 'à¶‘à¶šà·Š', 'à¶…à¶¯à·à¶±à¶ºà¶šà·Š', 'à¶¯,', 'à¶‘à¶šà·’à¶±à·™à¶š', 'à·ƒà¶½à·à¶­à¶ºà¶±à·Š', 'à¶‘à¶šà·’à¶±à·™à¶šà¶§', 'à·€à·™à¶±à·Š', 'à·€à·™à¶±à·Š', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶šà·à¶¸à¶­à·Š', 'à¶¯', 'à¶šà·’à·€', 'à·„à·à¶šà·’', 'à¶º.', '06.', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à¶º', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±à·Šà¶±à¶±à·Š,', 'à·ƒà¶½à·à¶­à¶º', 'à·ƒà¶¸à·Šà¶´à·–à¶»à·Šà¶«', 'à·€à·à¶ºà·™à¶±à·Š', 'à¶‰à¶§à·”', 'à¶šà¶»à¶±', 'à¶‰à¶¸à·à¶¸à·Šà·€à¶»à¶ºà·', 'à¶´à·’à·…à·’à¶´à·à¶¯à·’à¶º', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '**à¶…à¶·à·Š\\u200dà¶ºà·à·ƒ**', 'à¶´à·„à¶­', 'à¶´\\u200dà·Š\\u200dà¶»à¶šà·à·', 'à·„à¶»à·’', 'à¶±à¶¸à·Š', '(', 'âœ”', ')', 'à¶½à¶šà·”à¶«', 'à¶¯,', 'à·€à·à¶»à¶¯à·’', 'à¶±à¶¸à·Š', '(', 'x', ')', 'à¶½à¶šà·”à¶«', 'à¶¯', 'à·€à¶»à·„à¶±à·Š', 'à¶­à·”à·…', 'à¶ºà·œà¶¯à¶±à·Šà¶±.']\n",
      "\n",
      "Operation: REPLACE\n",
      "  GT indices:   [112:113] â†’ ['à¶…)']\n",
      "  Pred indices: [113:114] â†’ ['(à¶…)']\n",
      "\n",
      "Operation: EQUAL\n",
      "  GT indices:   [113:165] â†’ ['1.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·™à¶šà·”à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à¶´à·„à·ƒà·”', 'à¶±à¶¸à·Š', 'à¶šà¶½à·', 'à¶šà·…', 'à·„à·à¶šà·’', 'à¶º.', '2.', 'à·†à¶¢à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶º', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·„à·', 'à¶‘à¶šà¶­à·”', 'à¶šà¶»', 'à¶‰à¶§à·”à¶šà·…', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '3.', 'â€˜à¶¢à¶¸à·Šà¶‹', 'à¶­à¶šà·Šà¶¯à·“à¶¸à·Šâ€™', 'à¶ºà¶±à·”', 'à¶´à·™à¶»à¶§à·”', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸à¶ºà·’.', '4.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶šà·’à·ƒà·’', 'à¶¸', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶šà·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à·€à·à·Š\\u200dà¶º', 'à¶±à·œà·€à·š.', '(à¶†)', 'à¶”à¶¶', 'à¶¢à·“à·€à·’à¶­à¶ºà·š', 'à¶šà·ƒà·Šà¶»à·”', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·…', 'à¶…à¶­à·Šà¶¯à·à¶šà·“à¶¸à¶šà·Š', 'à¶šà·™à¶§à·’à¶ºà·™à¶±à·Š', 'à·€à·’à¶œ\\u200dà·Š\\u200dà¶»à·„', 'à¶šà¶»à¶±à·Šà¶±.']\n",
      "  Pred indices: [114:166] â†’ ['1.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à·™à¶šà·”à¶§', 'à·ƒà¶½à·à¶­à·Š', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à¶´à·„à·ƒà·”', 'à¶±à¶¸à·Š', 'à¶šà¶½à·', 'à¶šà·…', 'à·„à·à¶šà·’', 'à¶º.', '2.', 'à·†à¶¢à·Šà¶»à·Š', 'à·ƒà¶½à·à¶­à¶º', 'à¶šà·™à¶§à·’', 'à¶šà¶»', 'à·„à·', 'à¶‘à¶šà¶­à·”', 'à¶šà¶»', 'à¶‰à¶§à·”à¶šà·…', 'à¶±à·œà·„à·à¶šà·’', 'à¶º.', '3.', 'â€˜à¶¢à¶¸à·Šà¶‹', 'à¶­à¶šà·Šà¶¯à·“à¶¸à·Šâ€™', 'à¶ºà¶±à·”', 'à¶´à·™à¶»à¶§à·”', 'à¶šà¶»', 'à·ƒà¶½à·à¶­à·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸à¶ºà·’.', '4.', 'à¶œà¶¸à¶±à·™à·„à·’', 'à¶ºà·™à¶¯à·™à¶±à·Šà¶±à¶±à·Š', 'à¶šà·’à·ƒà·’', 'à¶¸', 'à·ƒà·”à¶±à·Šà¶±à¶­à·Š', 'à·ƒà¶½à·à¶­à¶ºà¶šà·Š', 'à¶‰à¶§à·”', 'à¶šà·’à¶»à·“à¶¸', 'à¶…à·€à·à·Š\\u200dà¶º', 'à¶±à·œà·€à·š.', '(à¶†)', 'à¶”à¶¶', 'à¶¢à·“à·€à·’à¶­à¶ºà·š', 'à¶šà·ƒà·Šà¶»à·”', 'à¶¢à¶¸à·Šà¶‹', 'à¶šà·…', 'à¶…à¶­à·Šà¶¯à·à¶šà·“à¶¸à¶šà·Š', 'à¶šà·™à¶§à·’à¶ºà·™à¶±à·Š', 'à·€à·’à¶œ\\u200dà·Š\\u200dà¶»à·„', 'à¶šà¶»à¶±à·Šà¶±.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Split into words\n",
    "gt_words = gt.split()\n",
    "pred_words = pred.split()\n",
    "\n",
    "print(\"Ground Truth words:\", gt_words)\n",
    "print(\"Prediction words:\", pred_words)\n",
    "print()\n",
    "\n",
    "# Create sequence matcher\n",
    "s = SequenceMatcher(None, gt_words, pred_words)\n",
    "\n",
    "# Get operations (opcodes)\n",
    "opcodes = s.get_opcodes()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"OPCODES EXPLAINED\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Format: (operation, gt_start, gt_end, pred_start, pred_end)\")\n",
    "print()\n",
    "\n",
    "for tag, i1, i2, j1, j2 in opcodes:\n",
    "    print(f\"Operation: {tag.upper()}\")\n",
    "    print(f\"  GT indices:   [{i1}:{i2}] â†’ {gt_words[i1:i2]}\")\n",
    "    print(f\"  Pred indices: [{j1}:{j2}] â†’ {pred_words[j1:j2]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f884f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from html import escape\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TextProcessor:\n",
    "    \"\"\"Shared utility class for text processing operations.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalizes text for comparison:\n",
    "        1. Removes markdown formatting (*, _, `) but KEEPS pipes | for tables.\n",
    "        2. Normalizes whitespace.\n",
    "        \"\"\"\n",
    "        text = re.sub(r'[*_`]', '', text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_markdown(text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Parses text into sections. \n",
    "        If no headers (#) are found, treats the whole text as a 'Whole Document' section.\n",
    "        \"\"\"\n",
    "        pattern = re.compile(r'(^|\\n)(#+)\\s*(.*?)(?=\\n#|\\Z)', re.DOTALL)\n",
    "        sections = {}\n",
    "        \n",
    "        matches = list(pattern.finditer(text))\n",
    "        \n",
    "        # FAILSAFE: If no headers found, treat entire text as body content\n",
    "        if not matches:\n",
    "            sections['Whole Document'] = {\n",
    "                'title': 'Whole Document',\n",
    "                'content': text.strip()\n",
    "            }\n",
    "            return sections\n",
    "\n",
    "        # If headers exist, parse normally\n",
    "        if matches[0].start() > 0:\n",
    "            preamble = text[:matches[0].start()].strip()\n",
    "            if preamble:\n",
    "                sections['PREAMBLE'] = {'title': 'PREAMBLE', 'content': preamble}\n",
    "\n",
    "        for match in matches:\n",
    "            hashes, title, content = match.group(2), match.group(3), match.group(0)\n",
    "            content_only = content.replace(f\"{hashes} {title}\", \"\", 1).strip()\n",
    "            \n",
    "            sections[title.strip()] = {\n",
    "                'title': title.strip(),\n",
    "                'content': content_only\n",
    "            }\n",
    "            \n",
    "        return sections\n",
    "\n",
    "\n",
    "class MarkdownEvaluator:\n",
    "    \"\"\"Evaluates similarity between ground truth and predicted markdown documents.\"\"\"\n",
    "    \n",
    "    def __init__(self, header_threshold=0.8):\n",
    "        self.header_threshold = header_threshold\n",
    "        self.processor = TextProcessor()\n",
    "\n",
    "    def evaluate(self, gt_text: str, pred_text: str) -> dict:\n",
    "        gt_sections = self.processor.parse_markdown(gt_text)\n",
    "        pred_sections = self.processor.parse_markdown(pred_text)\n",
    "\n",
    "        results = {'matches': [], 'score_sum': 0, 'count': 0}\n",
    "\n",
    "        def get_full_text(sec):\n",
    "            if sec['title'] == 'Whole Document':\n",
    "                return sec['content']\n",
    "            return f\"{sec['title']} {sec['content']}\"\n",
    "\n",
    "        matched_pred_keys = set()\n",
    "\n",
    "        for gt_key, gt_data in gt_sections.items():\n",
    "            best_match = None\n",
    "            best_score = 0.0\n",
    "            gt_full_clean = self.processor.clean_text(get_full_text(gt_data))\n",
    "\n",
    "            for pred_key, pred_data in pred_sections.items():\n",
    "                if pred_key in matched_pred_keys:\n",
    "                    continue\n",
    "\n",
    "                if gt_key == \"Whole Document\" or pred_key == \"Whole Document\":\n",
    "                    header_sim = 1.0\n",
    "                else:\n",
    "                    header_sim = SequenceMatcher(None, gt_key, pred_key).ratio()\n",
    "\n",
    "                if header_sim > self.header_threshold:\n",
    "                    pred_full_clean = self.processor.clean_text(get_full_text(pred_data))\n",
    "                    content_sim = SequenceMatcher(None, gt_full_clean, pred_full_clean).ratio()\n",
    "\n",
    "                    if content_sim > best_score:\n",
    "                        best_score = content_sim\n",
    "                        best_match = pred_key\n",
    "\n",
    "            if best_match:\n",
    "                matched_pred_keys.add(best_match)\n",
    "                gt_raw = self.processor.clean_text(get_full_text(gt_data))\n",
    "                pred_raw = self.processor.clean_text(get_full_text(pred_sections[best_match]))\n",
    "\n",
    "                results['matches'].append({\n",
    "                    'section': gt_key,\n",
    "                    'score': best_score,\n",
    "                    'gt_text': gt_raw,\n",
    "                    'pred_text': pred_raw\n",
    "                })\n",
    "                results['score_sum'] += best_score\n",
    "                results['count'] += 1\n",
    "            else:\n",
    "                results['matches'].append({\n",
    "                    'section': gt_key,\n",
    "                    'score': 0.0,\n",
    "                    'gt_text': self.processor.clean_text(get_full_text(gt_data)),\n",
    "                    'pred_text': ''\n",
    "                })\n",
    "                results['count'] += 1\n",
    "\n",
    "        results['final_score'] = results['score_sum'] / results['count'] if results['count'] > 0 else 0\n",
    "        return results\n",
    "\n",
    "\n",
    "class HTMLDiffGenerator:\n",
    "    \"\"\"Generates HTML diff visualization with Sinhala font support.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.processor = TextProcessor()\n",
    "        self.css = \"\"\"\n",
    "        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Sinhala:wght@400;600;700&display=swap');\n",
    "        \n",
    "        * {\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            box-sizing: border-box;\n",
    "        }\n",
    "        \n",
    "        body {\n",
    "            font-family: 'Noto Sans Sinhala', 'Iskoola Pota', 'Malithi Web', Arial, sans-serif;\n",
    "            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f0f23 100%);\n",
    "            min-height: 100vh;\n",
    "            padding: 20px;\n",
    "            line-height: 1.8;\n",
    "            color: #ffffff;\n",
    "        }\n",
    "        \n",
    "        .container {\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "        }\n",
    "        \n",
    "        .header {\n",
    "            background: rgba(255, 255, 255, 0.95);\n",
    "            border-radius: 16px;\n",
    "            padding: 24px 32px;\n",
    "            margin-bottom: 24px;\n",
    "            box-shadow: 0 10px 40px rgba(0,0,0,0.2);\n",
    "        }\n",
    "        \n",
    "        .header h1 {\n",
    "            font-size: 28px;\n",
    "            color: #1a1a2e;\n",
    "            margin-bottom: 8px;\n",
    "            font-weight: 700;\n",
    "        }\n",
    "        \n",
    "        .header .subtitle {\n",
    "            color: #666;\n",
    "            font-size: 14px;\n",
    "        }\n",
    "        \n",
    "        .score-card {\n",
    "            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);\n",
    "            border-radius: 12px;\n",
    "            padding: 20px 28px;\n",
    "            margin-bottom: 24px;\n",
    "            color: white;\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            box-shadow: 0 8px 32px rgba(17, 153, 142, 0.3);\n",
    "        }\n",
    "        \n",
    "        .score-card.low {\n",
    "            background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);\n",
    "        }\n",
    "        \n",
    "        .score-card.medium {\n",
    "            background: linear-gradient(135deg, #f7971e 0%, #ffd200 100%);\n",
    "        }\n",
    "        \n",
    "        .score-value {\n",
    "            font-size: 48px;\n",
    "            font-weight: 700;\n",
    "        }\n",
    "        \n",
    "        .score-label {\n",
    "            font-size: 16px;\n",
    "            opacity: 0.9;\n",
    "        }\n",
    "        \n",
    "        .legend {\n",
    "            background: rgba(255, 255, 255, 0.95);\n",
    "            border-radius: 12px;\n",
    "            padding: 16px 24px;\n",
    "            margin-bottom: 24px;\n",
    "            display: flex;\n",
    "            gap: 32px;\n",
    "            flex-wrap: wrap;\n",
    "            justify-content: center;\n",
    "            box-shadow: 0 4px 20px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        \n",
    "        .legend-item {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 8px;\n",
    "            font-size: 14px;\n",
    "            color: #333;\n",
    "        }\n",
    "        \n",
    "        .legend-color {\n",
    "            width: 24px;\n",
    "            height: 24px;\n",
    "            border-radius: 6px;\n",
    "            border: 2px solid;\n",
    "        }\n",
    "        \n",
    "        .legend-color.delete {\n",
    "            background: #fecaca;\n",
    "            border-color: #dc2626;\n",
    "        }\n",
    "        \n",
    "        .legend-color.insert {\n",
    "            background: #bbf7d0;\n",
    "            border-color: #16a34a;\n",
    "        }\n",
    "        \n",
    "        .legend-color.replace {\n",
    "            background: #fed7aa;\n",
    "            border-color: #ea580c;\n",
    "        }\n",
    "        \n",
    "        .legend-color.equal {\n",
    "            background: #ffffff;\n",
    "            border-color: #d1d5db;\n",
    "        }\n",
    "        \n",
    "        .section-card {\n",
    "            background: rgba(255, 255, 255, 0.95);\n",
    "            border-radius: 16px;\n",
    "            margin-bottom: 24px;\n",
    "            overflow: hidden;\n",
    "            box-shadow: 0 10px 40px rgba(0,0,0,0.15);\n",
    "        }\n",
    "        \n",
    "        .section-header {\n",
    "            background: linear-gradient(135deg, #2c3e50 0%, #3498db 100%);\n",
    "            color: white;\n",
    "            padding: 16px 24px;\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "        }\n",
    "        \n",
    "        .section-title {\n",
    "            font-size: 18px;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        \n",
    "        .section-score {\n",
    "            background: rgba(255,255,255,0.2);\n",
    "            padding: 6px 16px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 14px;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        \n",
    "        .diff-container {\n",
    "            display: grid;\n",
    "            grid-template-columns: 1fr 1fr;\n",
    "            gap: 0;\n",
    "        }\n",
    "        \n",
    "        .diff-column {\n",
    "            padding: 20px 24px;\n",
    "            min-height: 100px;\n",
    "        }\n",
    "        \n",
    "        .diff-column.gt {\n",
    "            background: #fefefe;\n",
    "            border-right: 2px solid #e5e7eb;\n",
    "        }\n",
    "        \n",
    "        .diff-column.pred {\n",
    "            background: #f9fafb;\n",
    "        }\n",
    "        \n",
    "        .column-header {\n",
    "            font-size: 12px;\n",
    "            font-weight: 700;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 1px;\n",
    "            margin-bottom: 16px;\n",
    "            padding-bottom: 8px;\n",
    "            border-bottom: 2px solid;\n",
    "        }\n",
    "        \n",
    "        .column-header.gt {\n",
    "            color: #dc2626;\n",
    "            border-color: #fecaca;\n",
    "        }\n",
    "        \n",
    "        .column-header.pred {\n",
    "            color: #16a34a;\n",
    "            border-color: #bbf7d0;\n",
    "        }\n",
    "        \n",
    "        .diff-content {\n",
    "            font-size: 16px;\n",
    "            line-height: 2;\n",
    "            word-wrap: break-word;\n",
    "            color: #374151;\n",
    "        }\n",
    "        \n",
    "        .word {\n",
    "            display: inline;\n",
    "            padding: 2px 0;\n",
    "            border-radius: 4px;\n",
    "            transition: all 0.2s ease;\n",
    "        }\n",
    "        \n",
    "        .word:hover {\n",
    "            transform: scale(1.05);\n",
    "        }\n",
    "        \n",
    "        .word.equal {\n",
    "            color: #374151;\n",
    "        }\n",
    "        \n",
    "        .word.delete {\n",
    "            background: #fecaca;\n",
    "            color: #991b1b;\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 4px;\n",
    "            border-bottom: 2px solid #dc2626;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        \n",
    "        .word.insert {\n",
    "            background: #bbf7d0;\n",
    "            color: #166534;\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 4px;\n",
    "            border-bottom: 2px solid #16a34a;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        \n",
    "        .word.replace {\n",
    "            background: #fed7aa;\n",
    "            color: #9a3412;\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 4px;\n",
    "            border-bottom: 2px solid #ea580c;\n",
    "            font-weight: 600;\n",
    "        }\n",
    "        \n",
    "        .stats-grid {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(4, 1fr);\n",
    "            gap: 16px;\n",
    "            margin-top: 24px;\n",
    "        }\n",
    "        \n",
    "        .stat-card {\n",
    "            background: rgba(255, 255, 255, 0.95);\n",
    "            border-radius: 12px;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 4px 20px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        \n",
    "        .stat-value {\n",
    "            font-size: 32px;\n",
    "            font-weight: 700;\n",
    "            color: #1a1a2e;\n",
    "        }\n",
    "        \n",
    "        .stat-label {\n",
    "            font-size: 12px;\n",
    "            color: #666;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 1px;\n",
    "            margin-top: 4px;\n",
    "        }\n",
    "        \n",
    "        .stat-card.delete .stat-value { color: #dc2626; }\n",
    "        .stat-card.insert .stat-value { color: #16a34a; }\n",
    "        .stat-card.replace .stat-value { color: #ea580c; }\n",
    "        .stat-card.equal .stat-value { color: #6b7280; }\n",
    "        \n",
    "        .empty-text {\n",
    "            color: #9ca3af;\n",
    "            font-style: italic;\n",
    "        }\n",
    "        \n",
    "        /* Responsive */\n",
    "        @media (max-width: 768px) {\n",
    "            .diff-container {\n",
    "                grid-template-columns: 1fr;\n",
    "            }\n",
    "            \n",
    "            .diff-column.gt {\n",
    "                border-right: none;\n",
    "                border-bottom: 2px solid #e5e7eb;\n",
    "            }\n",
    "            \n",
    "            .stats-grid {\n",
    "                grid-template-columns: repeat(2, 1fr);\n",
    "            }\n",
    "            \n",
    "            .legend {\n",
    "                gap: 16px;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        /* Print styles */\n",
    "        @media print {\n",
    "            body {\n",
    "                background: white;\n",
    "                padding: 0;\n",
    "            }\n",
    "            \n",
    "            .section-card {\n",
    "                break-inside: avoid;\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "    def get_diff_segments(self, gt_text: str, pred_text: str):\n",
    "        \"\"\"Get word-level diff with operation tags.\"\"\"\n",
    "        gt_words = gt_text.split() if gt_text else []\n",
    "        pred_words = pred_text.split() if pred_text else []\n",
    "        \n",
    "        s = SequenceMatcher(None, gt_words, pred_words)\n",
    "        \n",
    "        gt_segments = []\n",
    "        pred_segments = []\n",
    "        stats = {'equal': 0, 'delete': 0, 'insert': 0, 'replace': 0}\n",
    "        \n",
    "        for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "            if tag == 'equal':\n",
    "                for w in gt_words[i1:i2]:\n",
    "                    gt_segments.append((w, 'equal'))\n",
    "                    stats['equal'] += 1\n",
    "                for w in pred_words[j1:j2]:\n",
    "                    pred_segments.append((w, 'equal'))\n",
    "                    \n",
    "            elif tag == 'replace':\n",
    "                for w in gt_words[i1:i2]:\n",
    "                    gt_segments.append((w, 'replace'))\n",
    "                    stats['replace'] += 1\n",
    "                for w in pred_words[j1:j2]:\n",
    "                    pred_segments.append((w, 'replace'))\n",
    "                    \n",
    "            elif tag == 'delete':\n",
    "                for w in gt_words[i1:i2]:\n",
    "                    gt_segments.append((w, 'delete'))\n",
    "                    stats['delete'] += 1\n",
    "                    \n",
    "            elif tag == 'insert':\n",
    "                for w in pred_words[j1:j2]:\n",
    "                    pred_segments.append((w, 'insert'))\n",
    "                    stats['insert'] += 1\n",
    "        \n",
    "        return gt_segments, pred_segments, stats\n",
    "    \n",
    "    def render_segments(self, segments):\n",
    "        \"\"\"Render word segments as HTML spans.\"\"\"\n",
    "        if not segments:\n",
    "            return '<span class=\"empty-text\">(empty)</span>'\n",
    "        \n",
    "        html_parts = []\n",
    "        for word, tag in segments:\n",
    "            escaped_word = escape(word)\n",
    "            html_parts.append(\n",
    "                f'<span class=\"word {tag}\" title=\"{tag.upper()}\">{escaped_word}</span>'\n",
    "            )\n",
    "        \n",
    "        return ' '.join(html_parts)\n",
    "    \n",
    "    def get_score_class(self, score):\n",
    "        \"\"\"Get CSS class based on score.\"\"\"\n",
    "        if score >= 0.8:\n",
    "            return ''\n",
    "        elif score >= 0.5:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'low'\n",
    "    \n",
    "    def generate_html(self, metrics: dict, output_path: str = \"diff_report.html\"):\n",
    "        \"\"\"Generate complete HTML report.\"\"\"\n",
    "        \n",
    "        # Calculate total stats\n",
    "        total_stats = {'equal': 0, 'delete': 0, 'insert': 0, 'replace': 0}\n",
    "        sections_html = []\n",
    "        \n",
    "        for match in metrics['matches']:\n",
    "            gt_text = match.get('gt_text', '')\n",
    "            pred_text = match.get('pred_text', '')\n",
    "            \n",
    "            gt_segments, pred_segments, stats = self.get_diff_segments(gt_text, pred_text)\n",
    "            \n",
    "            for key in total_stats:\n",
    "                total_stats[key] += stats[key]\n",
    "            \n",
    "            section_html = f'''\n",
    "            <div class=\"section-card\">\n",
    "                <div class=\"section-header\">\n",
    "                    <span class=\"section-title\">{escape(match['section'])}</span>\n",
    "                    <span class=\"section-score\">Score: {match['score']:.1%}</span>\n",
    "                </div>\n",
    "                <div class=\"diff-container\">\n",
    "                    <div class=\"diff-column gt\">\n",
    "                        <div class=\"column-header gt\">Ground Truth</div>\n",
    "                        <div class=\"diff-content\">\n",
    "                            {self.render_segments(gt_segments)}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    <div class=\"diff-column pred\">\n",
    "                        <div class=\"column-header pred\">Prediction</div>\n",
    "                        <div class=\"diff-content\">\n",
    "                            {self.render_segments(pred_segments)}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            '''\n",
    "            sections_html.append(section_html)\n",
    "        \n",
    "        score_class = self.get_score_class(metrics['final_score'])\n",
    "        \n",
    "        html = f'''<!DOCTYPE html>\n",
    "<html lang=\"si\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Diff Visualization Report</title>\n",
    "    <style>\n",
    "        {self.css}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>Document Comparison Report</h1>\n",
    "            <div class=\"subtitle\">Generated on {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"legend\">\n",
    "            <div class=\"legend-item\">\n",
    "                <div class=\"legend-color delete\"></div>\n",
    "                <span>Deleted (in GT only)</span>\n",
    "            </div>\n",
    "            <div class=\"legend-item\">\n",
    "                <div class=\"legend-color insert\"></div>\n",
    "                <span>Inserted (in Pred only)</span>\n",
    "            </div>\n",
    "            <div class=\"legend-item\">\n",
    "                <div class=\"legend-color replace\"></div>\n",
    "                <span>Replaced/Changed</span>\n",
    "            </div>\n",
    "            <div class=\"legend-item\">\n",
    "                <div class=\"legend-color equal\"></div>\n",
    "                <span>Matched</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"stats-grid\">\n",
    "            <div class=\"stat-card equal\">\n",
    "                <div class=\"stat-value\">{total_stats['equal']}</div>\n",
    "                <div class=\"stat-label\">Words Matched</div>\n",
    "            </div>\n",
    "            <div class=\"stat-card delete\">\n",
    "                <div class=\"stat-value\">{total_stats['delete']}</div>\n",
    "                <div class=\"stat-label\">Words Deleted</div>\n",
    "            </div>\n",
    "            <div class=\"stat-card insert\">\n",
    "                <div class=\"stat-value\">{total_stats['insert']}</div>\n",
    "                <div class=\"stat-label\">Words Inserted</div>\n",
    "            </div>\n",
    "            <div class=\"stat-card replace\">\n",
    "                <div class=\"stat-value\">{total_stats['replace']}</div>\n",
    "                <div class=\"stat-label\">Words Replaced</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"margin-top: 32px;\">\n",
    "            {''.join(sections_html)}\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        // Add hover effects\n",
    "        document.querySelectorAll('.word:not(.equal)').forEach(word => {{\n",
    "            word.addEventListener('mouseenter', function() {{\n",
    "                this.style.transform = 'scale(1.1)';\n",
    "                this.style.boxShadow = '0 4px 12px rgba(0,0,0,0.15)';\n",
    "            }});\n",
    "            word.addEventListener('mouseleave', function() {{\n",
    "                this.style.transform = 'scale(1)';\n",
    "                this.style.boxShadow = 'none';\n",
    "            }});\n",
    "        }});\n",
    "    </script>\n",
    "</body>\n",
    "</html>'''\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        print(f\"HTML report saved: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Read test files\n",
    "    try:\n",
    "        with open(\"o.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            gt = f.read()\n",
    "        with open(\"p.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            pred = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Creating sample files...\\n\")\n",
    "        \n",
    "        gt = \"\"\"# Introduction\n",
    "This is a sample document with some text content.\n",
    "\n",
    "# Details\n",
    "Here are the details of the project.\n",
    "\"\"\"\n",
    "        \n",
    "        pred = \"\"\"# Introduction\n",
    "This is a sample document with different text content.\n",
    "\n",
    "# Details\n",
    "Here are some details about the project.\n",
    "\"\"\"\n",
    "        \n",
    "        with open(\"o.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(gt)\n",
    "        with open(\"p.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pred)\n",
    "        \n",
    "        print(\"Created o.txt and p.txt\\n\")\n",
    "    \n",
    "    # Evaluate using MarkdownEvaluator\n",
    "    evaluator = MarkdownEvaluator()\n",
    "    metrics = evaluator.evaluate(gt, pred)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Overall Score: {metrics['final_score']:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for match in metrics['matches']:\n",
    "        print(f\"\\nSection: {match['section']}\")\n",
    "        print(f\"   Score:   {match['score']:.4f}\")\n",
    "    \n",
    "    # Generate HTML using HTMLDiffGenerator\n",
    "    generator = HTMLDiffGenerator()\n",
    "    generator.generate_html(metrics, \"diff_report.html\")\n",
    "    \n",
    "    print(\"\\nOpen diff_report.html in your browser to view the results!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622cbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
